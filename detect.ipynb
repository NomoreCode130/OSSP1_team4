{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMbuJXDnBEamQgamijCbXA5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NomoreCode130/OSSP1_team4/blob/main/detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-85pGmhYl_JK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import numpy as np\n",
        "from model import Net\n",
        "import torch\n",
        "from imutils import face_utils"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = (34,26)\n",
        "PATH = './weights/trained.pth'\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "model = Net()\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()\n",
        "\n",
        "n_count = 0"
      ],
      "metadata": {
        "id": "ADbqLaRDrokh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_eye(img, eye_points):  #눈 부분 자르는 함수\n",
        "  x1, y1 = np.amin(eye_points, axis=0)\n",
        "  x2, y2 = np.amax(eye_points, axis=0)\n",
        "  cx, cy = (x1 + x2) / 2, (y1 + y2) / 2\n",
        "\n",
        "  w = (x2 - x1) * 1.2\n",
        "  h = w * IMG_SIZE[1] / IMG_SIZE[0]\n",
        "\n",
        "  margin_x, margin_y = w / 2, h / 2\n",
        "\n",
        "  min_x, min_y = int(cx - margin_x), int(cy - margin_y)\n",
        "  max_x, max_y = int(cx + margin_x), int(cy + margin_y)\n",
        "\n",
        "  eye_rect = np.rint([min_x, min_y, max_x, max_y]).astype(np.int)\n",
        "\n",
        "  eye_img = gray[eye_rect[1]:eye_rect[3], eye_rect[0]:eye_rect[2]]\n",
        "\n",
        "  return eye_img, eye_rect"
      ],
      "metadata": {
        "id": "rTsVUkTIrzZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(pred):  # 주어진 입력에 대한 모델의 예측 결과를 이진 형태로 반환하는 함수\n",
        "  pred = pred.transpose(1, 3).transpose(2, 3)\n",
        "\n",
        "  outputs = model(pred)\n",
        "\n",
        "  pred_tag = torch.round(torch.sigmoid(outputs))\n",
        "\n",
        "  return pred_tag"
      ],
      "metadata": {
        "id": "ZLGk4tyer7w5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while cap.isOpened():\n",
        "  ret, img_ori = cap.read()\n",
        "\n",
        "  if not ret:\n",
        "    break\n",
        "\n",
        "  img_ori = cv2.resize(img_ori, dsize=(0, 0), fx=0.5, fy=0.5)\n",
        "\n",
        "  img = img_ori.copy()\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  faces = detector(gray)\n",
        "\n",
        "  for face in faces:\n",
        "    shapes = predictor(gray, face)\n",
        "    shapes = face_utils.shape_to_np(shapes)\n",
        "\n",
        "    eye_img_l, eye_rect_l = crop_eye(gray, eye_points=shapes[36:42])\n",
        "    eye_img_r, eye_rect_r = crop_eye(gray, eye_points=shapes[42:48])\n",
        "\n",
        "\n",
        "    eye_img_l = cv2.resize(eye_img_l, dsize=IMG_SIZE)\n",
        "    eye_img_r = cv2.resize(eye_img_r, dsize=IMG_SIZE)\n",
        "    eye_img_r = cv2.flip(eye_img_r, flipCode=1)\n",
        "\n",
        "    cv2.imshow('l', eye_img_l)\n",
        "    cv2.imshow('r', eye_img_r)\n",
        "\n",
        "    eye_input_l = eye_img_l.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32)\n",
        "    eye_input_r = eye_img_r.copy().reshape((1, IMG_SIZE[1], IMG_SIZE[0], 1)).astype(np.float32)\n",
        "\n",
        "\n",
        "    eye_input_l = torch.from_numpy(eye_input_l)\n",
        "    eye_input_r = torch.from_numpy(eye_input_r)\n",
        "\n",
        "\n",
        "    pred_l = predict(eye_input_l)\n",
        "    pred_r = predict(eye_input_r)\n",
        "\n",
        "    if pred_l.item() == 0.0 and pred_r.item() == 0.0:\n",
        "      n_count+=1\n",
        "\n",
        "    else:\n",
        "      n_count = 0\n",
        "\n",
        "\n",
        "    if n_count > 100:\n",
        "      cv2.putText(img,\"Wake up\", (120,160), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255),2)\n",
        "\n",
        "\n",
        "\n",
        "    # visualize\n",
        "    state_l = 'O %.1f' if pred_l > 0.1 else '- %.1f'\n",
        "    state_r = 'O %.1f' if pred_r > 0.1 else '- %.1f'\n",
        "\n",
        "    state_l = state_l % pred_l\n",
        "    state_r = state_r % pred_r\n",
        "\n",
        "\n",
        "    cv2.rectangle(img, pt1=tuple(eye_rect_l[0:2]), pt2=tuple(eye_rect_l[2:4]), color=(255,255,255), thickness=2)\n",
        "    cv2.rectangle(img, pt1=tuple(eye_rect_r[0:2]), pt2=tuple(eye_rect_r[2:4]), color=(255,255,255), thickness=2)\n",
        "\n",
        "    cv2.putText(img, state_l, tuple(eye_rect_l[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "    cv2.putText(img, state_r, tuple(eye_rect_r[0:2]), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
        "\n",
        "  # print(state_l)\n",
        "  # print(state_r)\n",
        "  cv2.imshow('result', img)\n",
        "  cv2.waitKey(0)\n",
        "\n",
        "  if cv2.waitKey(1) == ord('q'):\n",
        "    break"
      ],
      "metadata": {
        "id": "G9OjwnBisa4d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}